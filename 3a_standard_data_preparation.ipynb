{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3a_standard_data_preparation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KYQXdo5scWW_","colab_type":"text"},"source":["# Creating Standard Training Data\n","\n","In this notebook we will be doing the following :\n","  1. Build & perform basic text cleaning operations/pipeline on the documents\n","  2. Convert the data in training data format. i.e. _label_tag1 _label_tag2\n","  3. Split the dataset into : train,dev and test sets  \n","  4.  Divide the dataset into Groups/Classes  \n","    a. Dividing the entire Dataset(~1M) into 14 groups/class.  \n","    b. Check the Label Distribution of Labels in each 14 groups/class.  \n","  5. Standard practices to Create Corpus & Label Dictionary using **Flair**\n","\n","**HOT TIP** : *Save them as pickle for easy rendering for experiments*\n","\n"]},{"cell_type":"code","metadata":{"id":"LILjzCaXcguK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"c8eb4180-babf-4884-bc75-887b7330adb6","executionInfo":{"status":"ok","timestamp":1578578546830,"user_tz":-330,"elapsed":5356,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}}},"source":["# First let's check what has Google given us ! Thank you Google for the GPU\n","\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Jan  9 14:02:24 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bGKB2JRvYnpx","colab_type":"code","outputId":"90d06c5a-c2a3-4c4d-e09b-f8d356a97303","executionInfo":{"status":"ok","timestamp":1578578888859,"user_tz":-330,"elapsed":1584,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Let's mount our G-Drive. Hey !! Because for GPU you now give your data to Google \n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LtRJwG4oLgWg","colab_type":"code","outputId":"a316b606-098a-4c5a-8ef9-6de0b970605e","executionInfo":{"status":"ok","timestamp":1578578697583,"user_tz":-330,"elapsed":86274,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Install necessary packages and restart the environment\n","\n","! pip install tiny-tokenizer\n","! pip install  flair"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tiny-tokenizer\n","  Downloading https://files.pythonhosted.org/packages/8d/0f/aa52c227c5af69914be05723b3deaf221805a4ccbce87643194ef2cdde43/tiny_tokenizer-3.1.0.tar.gz\n","Building wheels for collected packages: tiny-tokenizer\n","  Building wheel for tiny-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tiny-tokenizer: filename=tiny_tokenizer-3.1.0-cp36-none-any.whl size=10550 sha256=33a3ed6bd1d88a53ee9020f40c6384bc83d41ec63e79bbda122706d4e738250d\n","  Stored in directory: /root/.cache/pip/wheels/d1/c8/36/334497a689fab90128232e86b5829b800dd271a3d5d5959c53\n","Successfully built tiny-tokenizer\n","Installing collected packages: tiny-tokenizer\n","Successfully installed tiny-tokenizer-3.1.0\n","Collecting flair\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/22/8fc8e5978ec05b710216735ca47415700e83f304dec7e4281d61cefb6831/flair-0.4.4-py3-none-any.whl (193kB)\n","\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n","Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.2)\n","Collecting sqlitedict>=1.6.0\n","  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n","Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.3.1)\n","Collecting bpemb>=0.2.9\n","  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.2)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from flair) (3.10.0)\n","Collecting ipython==7.6.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n","\u001b[K     |████████████████████████████████| 778kB 41.7MB/s \n","\u001b[?25hRequirement already satisfied: tiny-tokenizer[all] in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.0)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n","Collecting mpld3==0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n","\u001b[K     |████████████████████████████████| 798kB 41.2MB/s \n","\u001b[?25hCollecting transformers>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\u001b[K     |████████████████████████████████| 450kB 45.3MB/s \n","\u001b[?25hCollecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n","\u001b[K     |████████████████████████████████| 1.0MB 39.5MB/s \n","\u001b[?25hRequirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n","Collecting segtok>=1.5.7\n","  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n","Collecting deprecated>=1.2.4\n","  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.22.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.17.5)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.12.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (6.2.2)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 35.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.21.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.6.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.1)\n","Collecting prompt-toolkit<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl (340kB)\n","\u001b[K     |████████████████████████████████| 348kB 38.7MB/s \n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.3)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (42.0.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n","Collecting janome; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/f0/bd7f90806132d7d9d642d418bdc3e870cfdff5947254ea3cab27480983a7/Janome-0.3.10-py2.py3-none-any.whl (21.5MB)\n","\u001b[K     |████████████████████████████████| 21.5MB 33.6MB/s \n","\u001b[?25hCollecting natto-py; extra == \"all\"\n","  Downloading https://files.pythonhosted.org/packages/f1/14/1d4258247a00b7b8a115563effb1d0bd30501d69580629d36593ce0af92d/natto-py-0.9.2.tar.gz\n","Collecting kytea; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/bc/702d01a96d5d094bd9f3c2eb1d12153daf8edf7bf5d78b9a2dae1202df07/kytea-0.1.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 33.1MB/s \n","\u001b[?25hCollecting SudachiPy; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/c9/40bfb291a7995ad218451ef97083432f998b822e3ecbd9f586f593d2cfb6/SudachiPy-0.4.2-py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n","\u001b[?25hCollecting SudachiDict-core@ https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz ; extra == \"all\"\n","\u001b[?25l  Downloading https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz (70.7MB)\n","\u001b[K     |████████████████████████████████| 70.7MB 132kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 33.5MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.10.47)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (8.0.2)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.3.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.14.1)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2019.11.28)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.8)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n","Requirement already satisfied: parso>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.2)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (1.13.2)\n","Collecting dartsclone~=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/7d/4d/45acbe9d0795d8ceef0fee1f9ac2dcbf27dca3a0578a023fcdc3fef6fd89/dartsclone-0.6.tar.gz\n","Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (2.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (7.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.9.4)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (1.13.47)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.2.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (2.19)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.6.0->SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.29.14)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers>=2.0.0->flair) (0.15.2)\n","Building wheels for collected packages: sqlitedict, mpld3, langdetect, segtok, natto-py, SudachiDict-core, sacremoses, dartsclone\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=4f1b5bd30211ceadad20c36aa2bfe33807bc017dc89ff8288087e9e372d6c227\n","  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=b578be544dd2ffcac68af9050f3ea786da77b54e2f04a8bd8e09c3af5b26f49c\n","  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=b15e693e431370dd47fd3c8cbb6274e02ae690eba645921894acb9be25ff028e\n","  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=3e6547e7e551d474cb309f6cce6917d99ec987ba6a3420f4bb9ffe487a1002b9\n","  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n","  Building wheel for natto-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for natto-py: filename=natto_py-0.9.2-cp36-none-any.whl size=45164 sha256=3a3f868db60ca43d63c391bb82d53ba640ddc87a321c050697242a71e301c62f\n","  Stored in directory: /root/.cache/pip/wheels/ce/51/dd/67f87608b124a23eecf5c1fc3557cc0b7ffdeae33fe6ee89df\n","  Building wheel for SudachiDict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for SudachiDict-core: filename=SudachiDict_core-20190927-cp36-none-any.whl size=70878518 sha256=14edfcaf0773e20157c7d5eefb77d4ebac89c5d07811c7a7ce6d083961bbc2d5\n","  Stored in directory: /root/.cache/pip/wheels/22/d8/6e/b107d7fef6e80915aa1e46db741b98a3da011f567526347ccc\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=b2a15526d20bc8bd939e7b9ea34ccb1efbe69cba02f136b43306c4433468dc03\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","  Building wheel for dartsclone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dartsclone: filename=dartsclone-0.6-cp36-cp36m-linux_x86_64.whl size=413260 sha256=52cce0616dbef6c3834458fcb349ca7eee4c56fa6bcfb28e18e43ebaaf57bf3f\n","  Stored in directory: /root/.cache/pip/wheels/be/cd/70/fe43307bf7398243155108f4f5a258ef336923d65ec4af93cd\n","Successfully built sqlitedict mpld3 langdetect segtok natto-py SudachiDict-core sacremoses dartsclone\n","\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n","Installing collected packages: sqlitedict, sentencepiece, bpemb, prompt-toolkit, ipython, mpld3, sacremoses, transformers, langdetect, segtok, deprecated, flair, janome, natto-py, kytea, dartsclone, SudachiPy, SudachiDict-core\n","  Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","Successfully installed SudachiDict-core-20190927 SudachiPy-0.4.2 bpemb-0.3.0 dartsclone-0.6 deprecated-1.2.7 flair-0.4.4 ipython-7.6.1 janome-0.3.10 kytea-0.1.4 langdetect-1.0.7 mpld3-0.3 natto-py-0.9.2 prompt-toolkit-2.0.10 sacremoses-0.0.38 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0 transformers-2.3.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9sZizSqp62NH","colab_type":"code","colab":{}},"source":["# Let's import our packages !\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import html\n","import re\n","from bs4 import BeautifulSoup\n","import re\n","from sklearn.model_selection import train_test_split\n","# import flair\n","import pickle\n","from torch.optim.adam import Adam\n","import json\n","# Making Corpus\n","\n","from flair.data import Corpus\n","from flair.datasets import ClassificationCorpus\n","from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrYBqDyFeM9v","colab_type":"code","colab":{}},"source":["## Mentioning where is our data located on G-Drive. Make sure to rectify your path\n","\n","path = '/content/drive/My Drive/ICDMAI_Tutorial/notebook/'\n","tag_group = '/content/drive/My Drive/ICDMAI_Tutorial/stack-overflow-tag-network/stack_network_nodes.csv'\n","data ='filtered_data/question_tag_text_mapping.pkl'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxJhWn1PeNSG","colab_type":"code","outputId":"e07ce598-eaa8-42c0-fb0e-1e361d9c1d1d","executionInfo":{"status":"ok","timestamp":1578578740869,"user_tz":-330,"elapsed":30920,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# Let's see the main Data-Set\n","\n","question_tag = pd.read_pickle(path+data)\n","question_tag.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>OwnerUserId</th>\n","      <th>CreationDate</th>\n","      <th>ClosedDate</th>\n","      <th>Score</th>\n","      <th>Title</th>\n","      <th>Body</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>120</td>\n","      <td>83.0</td>\n","      <td>2008-08-01T15:50:08Z</td>\n","      <td>NaN</td>\n","      <td>21</td>\n","      <td>ASP.NET Site Maps</td>\n","      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n","      <td>[sql, asp.net]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>260</td>\n","      <td>91.0</td>\n","      <td>2008-08-01T23:22:08Z</td>\n","      <td>NaN</td>\n","      <td>49</td>\n","      <td>Adding scripting functionality to .NET applica...</td>\n","      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n","      <td>[c#, .net]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>330</td>\n","      <td>63.0</td>\n","      <td>2008-08-02T02:51:36Z</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>Should I use nested classes in this case?</td>\n","      <td>&lt;p&gt;I am working on a collection of classes use...</td>\n","      <td>[c++]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>470</td>\n","      <td>71.0</td>\n","      <td>2008-08-02T15:11:47Z</td>\n","      <td>2016-03-26T05:23:29Z</td>\n","      <td>13</td>\n","      <td>Homegrown consumption of web services</td>\n","      <td>&lt;p&gt;I've been writing a few web services for a ...</td>\n","      <td>[web-services, .net]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>580</td>\n","      <td>91.0</td>\n","      <td>2008-08-02T23:30:59Z</td>\n","      <td>NaN</td>\n","      <td>21</td>\n","      <td>Deploying SQL Server Databases from Test to Live</td>\n","      <td>&lt;p&gt;I wonder how you guys manage deployment of ...</td>\n","      <td>[sql-server]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Id  ...                   Tag\n","0  120  ...        [sql, asp.net]\n","1  260  ...            [c#, .net]\n","2  330  ...                 [c++]\n","3  470  ...  [web-services, .net]\n","4  580  ...          [sql-server]\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"QpNjj0P8dddt","colab_type":"code","outputId":"5b3ee05c-2a19-48bf-e4bb-eddf57755bd9","executionInfo":{"status":"ok","timestamp":1578578741462,"user_tz":-330,"elapsed":29824,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# Let's see the Groups/Classes\n","import pandas as pd\n","tag_group = pd.read_csv(tag_group)\n","tag_group.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>group</th>\n","      <th>nodesize</th>\n","      <th>group_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c</td>\n","      <td>1</td>\n","      <td>189.83</td>\n","      <td>Programming</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>c++</td>\n","      <td>1</td>\n","      <td>268.11</td>\n","      <td>Programming</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>django</td>\n","      <td>1</td>\n","      <td>40.91</td>\n","      <td>Programming</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>python</td>\n","      <td>1</td>\n","      <td>438.67</td>\n","      <td>Programming</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>flask</td>\n","      <td>1</td>\n","      <td>9.39</td>\n","      <td>Programming</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     name  group  nodesize   group_name\n","0       c      1    189.83  Programming\n","1     c++      1    268.11  Programming\n","2  django      1     40.91  Programming\n","3  python      1    438.67  Programming\n","4   flask      1      9.39  Programming"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"CHS8mZmWc-h6","colab_type":"text"},"source":["## 1. Text Pre-processing Pipeline\n","\n","Every try-except block can be written as a different modular function which can be invoked from preprocess_text() function. This serves as a pipeline of the series of text-cleaning that you might require for your dataset."]},{"cell_type":"code","metadata":{"id":"X1qOCcSAQ-Og","colab_type":"code","colab":{}},"source":["clean = re.compile('<.*?>')\n","\n","def preprocess_text(text) :\n","  try :\n","    # soup = BeautifulSoup(text, \"html.parser\")\n","    # text = soup.get_text()\n","    text=  re.sub(clean, '', text)\n","    text = html.unescape(text)\n","  except :\n","    print(\"Error in HTML Processing ...\")\n","    print(text)\n","    text = text\n","  try :\n","    # remove extra newlines (often might be present in really noisy text)\n","    text = text.translate(text.maketrans(\"\\n\\t\\r\", \"   \"))\n","  except :\n","    print(\"Error in removing extra lines ...\")\n","    print(text)\n","    text = text\n","\n","  try :\n","    # remove extra whitespace\n","    text = re.sub(' +', ' ', text)\n","    text = text.strip()\n","  except :\n","    print(\"Error in extra whitespace removal ...\")\n","    print(text)\n","    text = text\n","\n","  return text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q0BxD9_GdENx","colab_type":"text"},"source":["## 2. Create Training Data Format\n","\n","Here we iterate the dataset dataframe and create the format acceptable to Flair. This is a standard format for few other Text Classification models/frameworks by Facebook.\n","\n","***Format***  : ____label ____**tag1** ____label ____**tag2** **text**\n","\n","Here the text Document has to be in a single line which was handled in the preprocess_text() method."]},{"cell_type":"code","metadata":{"id":"Ds6SmNxXjSxM","colab_type":"code","colab":{}},"source":["def create_training_format(question_tag) :\n","\n","  print(\"Preparing training data format ...\")\n","  # training_df = pd.DataFrame(\"columns\")\n","  labels = list()\n","  texts = list()\n","  for index in tqdm(question_tag.index) :\n","    tags = question_tag.loc[index,'Tag']\n","    text_label = ''\n","    for tag in tags :\n","      label = '__label__'+tag\n","      text_label = text_label + ' ' + label\n","    \n","    text_label = text_label.strip()\n","    # text =  html.unescape(question_tag.loc[index,'Body'])\n","    text =  question_tag.loc[index,'Title'].strip() + '. ' + question_tag.loc[index,'Body'].strip()\n","\n","    # if len(text.split()) < 5 :\n","    #   continue \n","\n","    labels.append(text_label)\n","    texts.append(text)\n","\n","\n","  df = pd.DataFrame(list(zip(labels[:], texts[:])), columns =['label', 'text']) \n","  # df.head()\n","  print(\"Cleaning Text ....\")\n","  df['text'] = df['text'].apply(preprocess_text)\n","  print(\"Cleaned Data Size : {}\".format(df.shape))\n","\n","  return df\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"utCSLYPHdKgm","colab_type":"text"},"source":["## 3. Create Training Splits\n","\n","Here we create standard random splits of the dataset to :\n","  1. training set : 70 % data\n","  2. dev/validation set :  15 % data\n","  3. test set : 15 % data\n","\n","#### TO DO : Experiments :\n","  1. Stratified Sampling of documents based on Tags\n","  2. Does a  70-15-15 split or 90-5-5 split make any difference when you have 1M records ?"]},{"cell_type":"code","metadata":{"id":"bbJT8_O5dK-S","colab_type":"code","colab":{}},"source":["def create_splits(df,path,group_id = ''):\n","\n","  print(\"Splitting Training Data ... \")\n","  train_df , test_df = train_test_split(df,random_state=42,test_size=0.30)\n","  dev_df ,test_df = train_test_split(test_df,random_state=42,test_size=0.5)\n","  print(\"Training Dataset : {}\".format(train_df.shape[0]))\n","  print(\"Validation Dataset : {}\".format(dev_df.shape[0]))\n","  print(\"Test Dataset : {}\".format(test_df.shape[0]))\n","\n","  print(\"Path  : {} \".format(path+'training_data/standard/group/'+ str(group_id) + '/train.txt'))\n","  train_df.to_csv(path+'training_data/standard/group/'+ str(group_id) + '/train.txt',sep='\\t',index=False,header=False)\n","  dev_df.to_csv(path+'training_data/standard/group/'+ str(group_id) + '/dev.txt',sep='\\t',index=False,header=False)\n","  test_df.to_csv(path+'training_data/standard/group/'+ str(group_id) + '/test.txt',sep='\\t',index=False,header=False)\n","\n","  return train_df,dev_df,test_df\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZIjUDgjTdj5J","colab_type":"text"},"source":["## 4. Divide the dataset into Groups/Classes\n","\n","Here we iterate over the entire dataset to create group level datasets in the following steps :\n","  1. Iterate over the groups and read the full-dataset eveytime\n","  2. Get all the tags in the group from the **tag_group** lookup\n","  3. Iterate over training examples and see if the labels fall in the same group\n","  4. Remove training examples which don't belong to the group\n","  5. Create the training data format of the remaining dataset\n","  6. Split & Save the dataset\n","\n","  ### TO DO :\n","    1. Make a single corpus for the entire dataset.\n"]},{"cell_type":"code","metadata":{"id":"PUQl8oD_eSn6","colab_type":"code","outputId":"97374f84-24d5-43c5-bee9-9794681ca697","executionInfo":{"status":"ok","timestamp":1578579885727,"user_tz":-330,"elapsed":297843,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for grp_id in range(1,15):\n","  \n","  ## 1. Iterate over the groups and read the full-dataset eveytime\n","  print(\"=================================================================\")\n","  print(\"Group ID being Processed : {}\".format(grp_id))\n","  print(\"=================================================================\")\n","  print(\"Reading Pickle File ...\")\n","\n","  question_tag = pd.read_pickle(path+data)\n","\n","  ## 2. Get all the tags in the group from the **tag_group** lookup  \n","\n","  group =  tag_group[tag_group.group == grp_id]\n","  labels = list(set(group['name']))\n","\n","  ## 3. Iterate over training examples and see if the labels fall in the same group\n","  for index in tqdm(question_tag.index):\n","    tags = question_tag.loc[index,'Tag']\n","    group_tags = list()\n","    for tag in tags :\n","      if tag in labels :\n","        group_tags.append(tag)\n","    question_tag.at[index,'Tag'] =  group_tags\n","  print(\"Before Removal of Blank Data : {} \".format(question_tag.shape))\n","\n","   ## 4. Remove training examples which don't belong to the group\n","  question_tag = question_tag[question_tag['Tag'].map(lambda d: len(d)) > 0]\n","  print(\"Final Data for Group ID  : {} is {}\".format(grp_id,question_tag.shape))\n","\n","  ## 5. Create the training data format of the remaining dataset\n","  training_data_format = create_training_format(question_tag)\n","\n","  ## 6. Split & Save the dataset\n","  train_df,dev_df,test_df = create_splits(training_data_format,path,group_id=grp_id)\n","\n","  print(\"=================================================================\")\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["=================================================================\n","Group ID being Processed : 1\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:44<00:00, 23823.81it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 3191/163030 [00:00<00:05, 31901.89it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 1 is (163030, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 163030/163030 [00:04<00:00, 33146.80it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (163030, 2)\n","Splitting Training Data ... \n","Training Dataset : 114121\n","Validation Dataset : 24454\n","Test Dataset : 24455\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/1/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 2\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:43<00:00, 24228.84it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 3065/196254 [00:00<00:06, 30648.57it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 2 is (196254, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 196254/196254 [00:06<00:00, 32375.24it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (196254, 2)\n","Splitting Training Data ... \n","Training Dataset : 137377\n","Validation Dataset : 29438\n","Test Dataset : 29439\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/2/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 3\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:43<00:00, 24008.42it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▍         | 3219/65453 [00:00<00:01, 32185.66it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 3 is (65453, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 65453/65453 [00:02<00:00, 32067.82it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (65453, 2)\n","Splitting Training Data ... \n","Training Dataset : 45817\n","Validation Dataset : 9818\n","Test Dataset : 9818\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/3/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 4\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:43<00:00, 24420.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 3046/169599 [00:00<00:05, 30454.00it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 4 is (169599, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 169599/169599 [00:05<00:00, 32466.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (169599, 2)\n","Splitting Training Data ... \n","Training Dataset : 118719\n","Validation Dataset : 25440\n","Test Dataset : 25440\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/4/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 5\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:44<00:00, 23892.67it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▌         | 3006/54356 [00:00<00:01, 30053.01it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 5 is (54356, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 54356/54356 [00:01<00:00, 32328.72it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (54356, 2)\n","Splitting Training Data ... \n","Training Dataset : 38049\n","Validation Dataset : 8153\n","Test Dataset : 8154\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/5/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 6\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:44<00:00, 23714.83it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 2734/356875 [00:00<00:12, 27336.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 6 is (356875, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 356875/356875 [00:11<00:00, 32225.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (356875, 2)\n","Splitting Training Data ... \n","Training Dataset : 249812\n","Validation Dataset : 53531\n","Test Dataset : 53532\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/6/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 7\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:43<00:00, 24275.77it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 3460/3460 [00:00<00:00, 33465.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 7 is (3460, 8)\n","Preparing training data format ...\n","Cleaning Text ....\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaned Data Size : (3460, 2)\n","Splitting Training Data ... \n","Training Dataset : 2422\n","Validation Dataset : 519\n","Test Dataset : 519\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/7/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 8\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:42<00:00, 24540.76it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 3146/143543 [00:00<00:04, 31454.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 8 is (143543, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 143543/143543 [00:04<00:00, 32565.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (143543, 2)\n","Splitting Training Data ... \n","Training Dataset : 100480\n","Validation Dataset : 21531\n","Test Dataset : 21532\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/8/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 9\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:44<00:00, 23447.54it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":[" 36%|███▌      | 3184/8850 [00:00<00:00, 31835.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 9 is (8850, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 8850/8850 [00:00<00:00, 31610.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (8850, 2)\n","Splitting Training Data ... \n","Training Dataset : 6195\n","Validation Dataset : 1327\n","Test Dataset : 1328\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/9/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 10\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:45<00:00, 23251.60it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|██▌       | 3270/12979 [00:00<00:00, 32695.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 10 is (12979, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 12979/12979 [00:00<00:00, 31265.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (12979, 2)\n","Splitting Training Data ... \n","Training Dataset : 9085\n","Validation Dataset : 1947\n","Test Dataset : 1947\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/10/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 11\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:43<00:00, 24290.52it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 5703/5703 [00:00<00:00, 31418.48it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 11 is (5703, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (5703, 2)\n","Splitting Training Data ... \n","Training Dataset : 3992\n","Validation Dataset : 855\n","Test Dataset : 856\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/11/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 12\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:45<00:00, 23314.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 570/570 [00:00<00:00, 26618.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 12 is (570, 8)\n","Preparing training data format ...\n","Cleaning Text ....\n","Cleaned Data Size : (570, 2)\n","Splitting Training Data ... \n","Training Dataset : 399\n","Validation Dataset : 85\n","Test Dataset : 86\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/12/train.txt \n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================================\n","=================================================================\n","Group ID being Processed : 13\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:45<00:00, 23203.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":[" 17%|█▋        | 3371/19933 [00:00<00:00, 33703.44it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 13 is (19933, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 19933/19933 [00:00<00:00, 31861.69it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (19933, 2)\n","Splitting Training Data ... \n","Training Dataset : 13953\n","Validation Dataset : 2990\n","Test Dataset : 2990\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/13/train.txt \n","=================================================================\n","=================================================================\n","Group ID being Processed : 14\n","=================================================================\n","Reading Pickle File ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1051992/1051992 [00:44<00:00, 23495.44it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Before Removal of Blank Data : (1051992, 8) \n"],"name":"stdout"},{"output_type":"stream","text":[" 23%|██▎       | 3324/14291 [00:00<00:00, 33233.46it/s]"],"name":"stderr"},{"output_type":"stream","text":["Final Data for Group ID  : 14 is (14291, 8)\n","Preparing training data format ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 14291/14291 [00:00<00:00, 31517.53it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Cleaning Text ....\n","Cleaned Data Size : (14291, 2)\n","Splitting Training Data ... \n","Training Dataset : 10003\n","Validation Dataset : 2144\n","Test Dataset : 2144\n","Path  : /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/14/train.txt \n","=================================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VxJTJlRAfCJO","colab_type":"text"},"source":["## 5. Create Corpus & Label Dictionary : Flair Corpus\n","\n","For all the training splits created above for each group, we will be creating a corpus & vocabulary to train a different model.\n","  1. First we load the train, dev, test dataset and create corpus using ClassificationCorpus\n","  2. label dictionary is created using make_label_dictionary\n","  3. saving corpus and dictionary dumps for easy retrieval"]},{"cell_type":"code","metadata":{"id":"mE1VjpMKdHyY","colab_type":"code","outputId":"ec68a619-cee0-4256-bb06-136629748b8e","executionInfo":{"status":"ok","timestamp":1578591993582,"user_tz":-330,"elapsed":10191145,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["path = '/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/'\n","\n","for grp in range(1,15):\n","  \n","  print(\"=================================================================\")\n","  print(\"Group ID being Processed : {}\".format(grp))\n","  print(\"=================================================================\")\n","  \n","  # this is the folder in which train, test and dev files reside\n","  data_folder =path+str(grp)+'/'\n","  print(data_folder)\n","\n","  print(\"Creating Corpus ...\")\n","  # load corpus containing training, test and dev data\n","  corpus: Corpus = ClassificationCorpus(data_folder,\n","                                        test_file='test.txt',\n","                                        dev_file='dev.txt',\n","                                        train_file='train.txt')\n","\n","  # 2. create the label dictionary\n","  label_dict = corpus.make_label_dictionary()\n","\n","  print(\"Obtaining Corpus Statisitics...\")\n","  stats  = corpus.obtain_statistics()\n","  json_stats = json.loads(stats)\n","\n","  print(json_stats)\n","  \n","  with open(data_folder+'corpus_statistics.json', 'w') as f:\n","    json.dump(json_stats, f)\n","\n","  print(\"Creating Dumps ... \")\n","  with open(data_folder+'classification_corpus.pkl',mode='wb') as f :\n","    pickle.dump(corpus,f)\n","\n","  with open(data_folder + 'classification_corpus_label_dict.pkl',mode='wb') as f:\n","    pickle.dump(label_dict,f)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["=================================================================\n","Group ID being Processed : 1\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/1/\n","Creating Corpus ...\n","2020-01-09 14:56:43,336 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/1\n","2020-01-09 14:56:43,343 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/1/train.txt\n","2020-01-09 14:56:43,346 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/1/dev.txt\n","2020-01-09 14:56:43,349 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/1/test.txt\n","2020-01-09 14:56:45,511 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 114121/114121 [05:56<00:00, 319.89it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 15:02:42,757 [b'python', b'django', b'r', b'c', b'c++', b'matlab', b'qt', b'embedded', b'machine-learning', b'flask']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 114121, 'number_of_documents_per_class': {'python': 45294, 'django': 8957, 'r': 11005, 'c': 16255, 'c++': 33272, 'matlab': 4553, 'qt': 3733, 'embedded': 421, 'machine-learning': 870, 'flask': 993}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 19629187, 'min': 9, 'max': 5701, 'avg': 172.00328598592722}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 24455, 'number_of_documents_per_class': {'r': 2425, 'c++': 7070, 'c': 3482, 'python': 9620, 'django': 1929, 'matlab': 990, 'machine-learning': 176, 'qt': 843, 'flask': 201, 'embedded': 96}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 4211200, 'min': 9, 'max': 3518, 'avg': 172.20200368022898}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 24454, 'number_of_documents_per_class': {'r': 2271, 'c': 3501, 'python': 9687, 'c++': 7249, 'django': 1932, 'matlab': 952, 'qt': 808, 'flask': 213, 'machine-learning': 182, 'embedded': 74}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 4183418, 'min': 9, 'max': 2941, 'avg': 171.0729533000736}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 2\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/2/\n","Creating Corpus ...\n","2020-01-09 15:19:43,849 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/2\n","2020-01-09 15:19:43,850 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/2/train.txt\n","2020-01-09 15:19:43,852 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/2/dev.txt\n","2020-01-09 15:19:43,854 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/2/test.txt\n","2020-01-09 15:19:50,293 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 137377/137377 [06:42<00:00, 341.55it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 15:26:32,991 [b'sql', b'sql-server', b'wpf', b'.net', b'c#', b'visual-studio', b'wcf', b'unity3d', b'asp.net', b'vb.net', b'asp.net-web-api', b'oracle', b'entity-framework', b'azure', b'linq', b'xamarin', b'plsql']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 137377, 'number_of_documents_per_class': {'sql': 25022, 'sql-server': 12726, 'wpf': 8738, '.net': 16884, 'c#': 70995, 'visual-studio': 4296, 'wcf': 3120, 'unity3d': 1378, 'asp.net': 20960, 'vb.net': 7162, 'asp.net-web-api': 1370, 'oracle': 5277, 'entity-framework': 4266, 'azure': 2443, 'linq': 4125, 'xamarin': 1198, 'plsql': 958}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 22224504, 'min': 8, 'max': 4001, 'avg': 161.77747366735335}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 29439, 'number_of_documents_per_class': {'azure': 511, 'asp.net': 4485, '.net': 3590, 'oracle': 1192, 'c#': 15030, 'wpf': 1845, 'sql': 5354, 'linq': 942, 'sql-server': 2791, 'entity-framework': 912, 'wcf': 708, 'vb.net': 1575, 'asp.net-web-api': 321, 'visual-studio': 940, 'unity3d': 308, 'xamarin': 259, 'plsql': 219}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 4753046, 'min': 11, 'max': 5701, 'avg': 161.45405754271545}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 29438, 'number_of_documents_per_class': {'xamarin': 258, 'c#': 15161, 'linq': 938, 'azure': 535, 'sql': 5406, 'sql-server': 2643, '.net': 3585, 'wpf': 1782, 'asp.net': 4525, 'entity-framework': 896, 'vb.net': 1549, 'wcf': 652, 'oracle': 1176, 'visual-studio': 913, 'unity3d': 314, 'plsql': 224, 'asp.net-web-api': 282}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 4782172, 'min': 8, 'max': 3341, 'avg': 162.4489435423602}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 3\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/3/\n","Creating Corpus ...\n","2020-01-09 15:46:21,007 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/3\n","2020-01-09 15:46:21,008 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/3/train.txt\n","2020-01-09 15:46:21,014 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/3/dev.txt\n","2020-01-09 15:46:21,016 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/3/test.txt\n","2020-01-09 15:46:23,125 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 45817/45817 [02:15<00:00, 339.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 15:48:38,748 [b'node.js', b'ruby-on-rails', b'mongodb', b'ruby', b'express', b'elasticsearch', b'reactjs', b'redux', b'postgresql', b'redis', b'react-native']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 45817, 'number_of_documents_per_class': {'node.js': 10053, 'ruby-on-rails': 18170, 'mongodb': 5001, 'ruby': 12027, 'express': 1844, 'elasticsearch': 1481, 'reactjs': 1782, 'redux': 276, 'postgresql': 4112, 'redis': 705, 'react-native': 554}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 7366580, 'min': 8, 'max': 4819, 'avg': 160.78267891830544}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 9818, 'number_of_documents_per_class': {'ruby': 2512, 'elasticsearch': 329, 'ruby-on-rails': 3821, 'node.js': 2227, 'reactjs': 379, 'postgresql': 919, 'mongodb': 1030, 'react-native': 120, 'express': 415, 'redis': 139, 'redux': 52}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 1586708, 'min': 15, 'max': 2428, 'avg': 161.61214096557345}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 9818, 'number_of_documents_per_class': {'ruby-on-rails': 3798, 'postgresql': 910, 'node.js': 2245, 'reactjs': 400, 'ruby': 2474, 'mongodb': 1053, 'redis': 166, 'elasticsearch': 321, 'express': 447, 'react-native': 110, 'redux': 62}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 1568096, 'min': 12, 'max': 3117, 'avg': 159.7164391933184}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 4\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/4/\n","Creating Corpus ...\n","2020-01-09 15:55:16,989 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/4\n","2020-01-09 15:55:16,991 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/4/train.txt\n","2020-01-09 15:55:16,992 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/4/dev.txt\n","2020-01-09 15:55:16,995 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/4/test.txt\n","2020-01-09 15:55:23,933 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 118719/118719 [06:12<00:00, 319.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 16:01:36,564 [b'iphone', b'ios', b'android', b'objective-c', b'xcode', b'osx', b'swift', b'android-studio']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 118719, 'number_of_documents_per_class': {'iphone': 15101, 'ios': 32761, 'android': 63447, 'objective-c': 18776, 'xcode': 7440, 'osx': 5081, 'swift': 8287, 'android-studio': 2190}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 20278283, 'min': 8, 'max': 3665, 'avg': 170.80907858051364}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 25440, 'number_of_documents_per_class': {'swift': 1749, 'ios': 7080, 'iphone': 3204, 'objective-c': 4056, 'android': 13609, 'osx': 1070, 'android-studio': 476, 'xcode': 1564}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 4341168, 'min': 11, 'max': 2572, 'avg': 170.6433962264151}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 25440, 'number_of_documents_per_class': {'xcode': 1629, 'ios': 7168, 'osx': 1092, 'android': 13603, 'iphone': 3234, 'objective-c': 4090, 'swift': 1796, 'android-studio': 488}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 4327989, 'min': 10, 'max': 3074, 'avg': 170.12535377358492}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 5\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/5/\n","Creating Corpus ...\n","2020-01-09 16:19:43,503 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/5\n","2020-01-09 16:19:43,504 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/5/train.txt\n","2020-01-09 16:19:43,505 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/5/dev.txt\n","2020-01-09 16:19:43,506 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/5/test.txt\n","2020-01-09 16:19:45,032 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 38049/38049 [01:45<00:00, 360.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 16:21:31,025 [b'unix', b'git', b'windows', b'apache', b'shell', b'bash', b'linux', b'github', b'ubuntu', b'powershell', b'nginx']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 38049, 'number_of_documents_per_class': {'unix': 2243, 'git': 5310, 'windows': 7108, 'apache': 4693, 'shell': 3524, 'bash': 5196, 'linux': 9332, 'github': 1526, 'ubuntu': 2147, 'powershell': 2724, 'nginx': 1493}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 5695655, 'min': 10, 'max': 3502, 'avg': 149.6926331835265}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 8154, 'number_of_documents_per_class': {'linux': 2052, 'ubuntu': 493, 'bash': 1152, 'apache': 965, 'git': 1163, 'powershell': 527, 'windows': 1533, 'shell': 723, 'nginx': 324, 'unix': 437, 'github': 318}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 1196924, 'min': 10, 'max': 3215, 'avg': 146.78979641893548}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 8153, 'number_of_documents_per_class': {'linux': 2011, 'unix': 475, 'git': 1153, 'ubuntu': 489, 'windows': 1501, 'powershell': 603, 'bash': 1136, 'github': 315, 'apache': 1000, 'shell': 744, 'nginx': 293}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 1219189, 'min': 11, 'max': 3433, 'avg': 149.53869741199557}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 6\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/6/\n","Creating Corpus ...\n","2020-01-09 16:26:50,976 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/6\n","2020-01-09 16:26:50,978 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/6/train.txt\n","2020-01-09 16:26:50,980 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/6/dev.txt\n","2020-01-09 16:26:50,981 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/6/test.txt\n","2020-01-09 16:27:01,359 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 249812/249812 [12:11<00:00, 341.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 16:39:13,622 [b'php', b'mysql', b'json', b'html', b'jquery', b'javascript', b'angularjs', b'css', b'twitter-bootstrap-3', b'twitter-bootstrap', b'ajax', b'xml', b'laravel', b'wordpress', b'less', b'codeigniter', b'drupal', b'html5', b'vue.js', b'sass', b'ionic-framework', b'photoshop']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 249812, 'number_of_documents_per_class': {'php': 69172, 'mysql': 29751, 'json': 12281, 'html': 41206, 'jquery': 55075, 'javascript': 87098, 'angularjs': 14200, 'css': 29721, 'twitter-bootstrap-3': 1153, 'twitter-bootstrap': 5052, 'ajax': 10957, 'xml': 10277, 'laravel': 3409, 'wordpress': 6969, 'less': 390, 'codeigniter': 3412, 'drupal': 1187, 'html5': 6635, 'vue.js': 151, 'sass': 659, 'ionic-framework': 1071, 'photoshop': 124}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 40194666, 'min': 6, 'max': 4819, 'avg': 160.89966054472964}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 53532, 'number_of_documents_per_class': {'javascript': 18551, 'css': 6328, 'jquery': 11839, 'twitter-bootstrap': 1072, 'html': 8899, 'php': 14782, 'mysql': 6273, 'angularjs': 3086, 'laravel': 776, 'xml': 2267, 'html5': 1396, 'json': 2665, 'ajax': 2381, 'codeigniter': 726, 'wordpress': 1486, 'photoshop': 33, 'drupal': 268, 'twitter-bootstrap-3': 260, 'ionic-framework': 222, 'less': 82, 'sass': 141, 'vue.js': 41}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 8599246, 'min': 11, 'max': 3575, 'avg': 160.63748785772995}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 53531, 'number_of_documents_per_class': {'css': 6259, 'jquery': 11628, 'html': 8871, 'javascript': 18506, 'php': 14854, 'angularjs': 3059, 'mysql': 6440, 'ajax': 2291, 'wordpress': 1458, 'photoshop': 32, 'html5': 1533, 'xml': 2219, 'json': 2723, 'sass': 147, 'laravel': 711, 'ionic-framework': 214, 'codeigniter': 754, 'twitter-bootstrap': 1037, 'drupal': 267, 'less': 82, 'twitter-bootstrap-3': 245, 'vue.js': 22}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 8597679, 'min': 11, 'max': 3612, 'avg': 160.6112159309559}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 7\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/7/\n","Creating Corpus ...\n","2020-01-09 17:15:41,026 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/7\n","2020-01-09 17:15:41,032 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/7/train.txt\n","2020-01-09 17:15:41,035 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/7/dev.txt\n","2020-01-09 17:15:41,036 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/7/test.txt\n","2020-01-09 17:15:41,096 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2422/2422 [00:07<00:00, 327.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:15:48,970 [b'typescript', b'angular2']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 2422, 'number_of_documents_per_class': {'typescript': 1210, 'angular2': 1598}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 397679, 'min': 18, 'max': 2423, 'avg': 164.19446738232867}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 519, 'number_of_documents_per_class': {'typescript': 283, 'angular2': 321}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 88052, 'min': 14, 'max': 1526, 'avg': 169.65703275529864}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 519, 'number_of_documents_per_class': {'typescript': 270, 'angular2': 340}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 88473, 'min': 15, 'max': 1104, 'avg': 170.46820809248555}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 8\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/8/\n","Creating Corpus ...\n","2020-01-09 17:16:11,179 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/8\n","2020-01-09 17:16:11,180 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/8/train.txt\n","2020-01-09 17:16:11,185 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/8/dev.txt\n","2020-01-09 17:16:11,189 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/8/test.txt\n","2020-01-09 17:16:13,045 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100480/100480 [05:39<00:00, 295.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:21:53,127 [b'java', b'spring', b'rest', b'web-services', b'hibernate', b'eclipse', b'api', b'jsp', b'maven', b'java-ee', b'spring-boot', b'spring-mvc']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 100480, 'number_of_documents_per_class': {'java': 80609, 'spring': 6941, 'rest': 3432, 'web-services': 3754, 'hibernate': 4081, 'eclipse': 7040, 'api': 3395, 'jsp': 3009, 'maven': 3313, 'java-ee': 1878, 'spring-boot': 924, 'spring-mvc': 2656}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 18549783, 'min': 7, 'max': 10740, 'avg': 184.61169386942674}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 21532, 'number_of_documents_per_class': {'eclipse': 1428, 'java': 17306, 'api': 720, 'rest': 755, 'web-services': 818, 'maven': 678, 'hibernate': 918, 'spring': 1478, 'jsp': 660, 'spring-mvc': 571, 'spring-boot': 208, 'java-ee': 376}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 3982212, 'min': 8, 'max': 4137, 'avg': 184.94389745495076}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 21531, 'number_of_documents_per_class': {'java': 17297, 'api': 788, 'rest': 729, 'hibernate': 875, 'eclipse': 1427, 'spring': 1516, 'spring-mvc': 549, 'jsp': 643, 'java-ee': 380, 'maven': 684, 'web-services': 745, 'spring-boot': 190}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 3991621, 'min': 10, 'max': 5690, 'avg': 185.38948492870745}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 9\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/9/\n","Creating Corpus ...\n","2020-01-09 17:37:59,717 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/9\n","2020-01-09 17:37:59,720 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/9/train.txt\n","2020-01-09 17:37:59,721 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/9/dev.txt\n","2020-01-09 17:37:59,723 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/9/test.txt\n","2020-01-09 17:37:59,846 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6195/6195 [00:19<00:00, 310.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:38:20,268 [b'jenkins', b'amazon-web-services', b'docker', b'cloud', b'go', b'devops']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 6195, 'number_of_documents_per_class': {'jenkins': 1289, 'amazon-web-services': 2231, 'docker': 1123, 'cloud': 291, 'go': 1323, 'devops': 47}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 955937, 'min': 18, 'max': 2267, 'avg': 154.30782889426956}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 1328, 'number_of_documents_per_class': {'jenkins': 270, 'amazon-web-services': 478, 'go': 265, 'docker': 252, 'devops': 12, 'cloud': 76}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 205314, 'min': 12, 'max': 1219, 'avg': 154.6039156626506}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 1327, 'number_of_documents_per_class': {'amazon-web-services': 481, 'go': 270, 'docker': 247, 'jenkins': 283, 'cloud': 58, 'devops': 3}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 212073, 'min': 21, 'max': 2549, 'avg': 159.81386586284853}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 10\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/10/\n","Creating Corpus ...\n","2020-01-09 17:39:14,057 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/10\n","2020-01-09 17:39:14,062 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/10/train.txt\n","2020-01-09 17:39:14,064 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/10/dev.txt\n","2020-01-09 17:39:14,065 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/10/test.txt\n","2020-01-09 17:39:14,248 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 9085/9085 [00:26<00:00, 339.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:39:41,511 [b'hadoop', b'scala', b'haskell', b'apache-spark']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 9085, 'number_of_documents_per_class': {'hadoop': 2145, 'scala': 4011, 'haskell': 2120, 'apache-spark': 1389}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 1499702, 'min': 11, 'max': 3107, 'avg': 165.07451843698405}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 1947, 'number_of_documents_per_class': {'scala': 856, 'haskell': 433, 'hadoop': 485, 'apache-spark': 285}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 330290, 'min': 17, 'max': 3163, 'avg': 169.64047252182846}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 1947, 'number_of_documents_per_class': {'scala': 809, 'apache-spark': 302, 'haskell': 490, 'hadoop': 469}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 325000, 'min': 20, 'max': 4048, 'avg': 166.92347200821777}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 11\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/11/\n","Creating Corpus ...\n","2020-01-09 17:41:03,655 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/11\n","2020-01-09 17:41:03,660 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/11/train.txt\n","2020-01-09 17:41:03,662 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/11/dev.txt\n","2020-01-09 17:41:03,665 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/11/test.txt\n","2020-01-09 17:41:03,743 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 3992/3992 [00:14<00:00, 279.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:41:18,554 [b'selenium', b'testing']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 3992, 'number_of_documents_per_class': {'selenium': 2388, 'testing': 1708}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 587267, 'min': 15, 'max': 1736, 'avg': 147.11097194388776}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 856, 'number_of_documents_per_class': {'testing': 392, 'selenium': 486}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 127064, 'min': 19, 'max': 1918, 'avg': 148.4392523364486}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 855, 'number_of_documents_per_class': {'selenium': 499, 'testing': 371}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 124647, 'min': 11, 'max': 930, 'avg': 145.7859649122807}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 12\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/12/\n","Creating Corpus ...\n","2020-01-09 17:41:53,979 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/12\n","2020-01-09 17:41:53,982 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/12/train.txt\n","2020-01-09 17:41:53,986 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/12/dev.txt\n","2020-01-09 17:41:53,990 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/12/test.txt\n","2020-01-09 17:41:54,007 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 399/399 [00:01<00:00, 323.40it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:41:55,742 [b'agile', b'tdd']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 399, 'number_of_documents_per_class': {'agile': 90, 'tdd': 311}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 63426, 'min': 14, 'max': 901, 'avg': 158.9624060150376}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 86, 'number_of_documents_per_class': {'tdd': 68, 'agile': 19}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 12223, 'min': 28, 'max': 422, 'avg': 142.12790697674419}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 85, 'number_of_documents_per_class': {'tdd': 68, 'agile': 18}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 12426, 'min': 29, 'max': 412, 'avg': 146.18823529411765}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 13\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/13/\n","Creating Corpus ...\n","2020-01-09 17:42:00,107 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/13\n","2020-01-09 17:42:00,110 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/13/train.txt\n","2020-01-09 17:42:00,114 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/13/dev.txt\n","2020-01-09 17:42:00,116 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/13/test.txt\n","2020-01-09 17:42:00,450 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 13953/13953 [00:36<00:00, 380.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:42:37,646 [b'regex', b'perl']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 13953, 'number_of_documents_per_class': {'regex': 10732, 'perl': 3657}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 1784337, 'min': 10, 'max': 2886, 'avg': 127.8819608686304}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 2990, 'number_of_documents_per_class': {'regex': 2277, 'perl': 800}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 381849, 'min': 19, 'max': 2374, 'avg': 127.70869565217392}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 2990, 'number_of_documents_per_class': {'regex': 2340, 'perl': 749}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 373761, 'min': 7, 'max': 2168, 'avg': 125.00367892976588}}}\n","Creating Dumps ... \n","=================================================================\n","Group ID being Processed : 14\n","=================================================================\n","/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/14/\n","Creating Corpus ...\n","2020-01-09 17:44:27,708 Reading data from /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/14\n","2020-01-09 17:44:27,710 Train: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/14/train.txt\n","2020-01-09 17:44:27,716 Dev: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/14/dev.txt\n","2020-01-09 17:44:27,718 Test: /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/standard/group/14/test.txt\n","2020-01-09 17:44:27,917 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10003/10003 [00:33<00:00, 302.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-09 17:45:01,509 [b'excel', b'vba', b'excel-vba']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Obtaining Corpus Statisitics...\n","{'TRAIN': {'dataset': 'TRAIN', 'total_number_of_documents': 10003, 'number_of_documents_per_class': {'excel': 7261, 'vba': 4773, 'excel-vba': 3682}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 1741069, 'min': 10, 'max': 2934, 'avg': 174.05468359492153}}, 'TEST': {'dataset': 'TEST', 'total_number_of_documents': 2144, 'number_of_documents_per_class': {'excel': 1542, 'vba': 1087, 'excel-vba': 778}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 369777, 'min': 19, 'max': 2135, 'avg': 172.47061567164178}}, 'DEV': {'dataset': 'DEV', 'total_number_of_documents': 2144, 'number_of_documents_per_class': {'vba': 1032, 'excel-vba': 743, 'excel': 1581}, 'number_of_tokens_per_tag': {}, 'number_of_tokens': {'total': 368862, 'min': 14, 'max': 4458, 'avg': 172.04384328358208}}}\n","Creating Dumps ... \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XQKcxpXFuI_-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}