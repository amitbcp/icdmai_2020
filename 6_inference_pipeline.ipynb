{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S10Vu9D_HTxK"
   },
   "source": [
    "# Perdiction Pipeline | Ensemble Pipeline\n",
    "\n",
    "In this notebook, we will ensemble our models to make a prediction pipeline.\n",
    "The keys steps would be as following :\n",
    "\n",
    "  1. Text Preprocessing for inference.\n",
    "  2. Load classifiers iteratively in a list.\n",
    "  3. Load test-data & pre-process.\n",
    "  4. Set classifier threshold and run it through Ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3352,
     "status": "ok",
     "timestamp": 1577801663441,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "tWSz_ii0ZUiL",
    "outputId": "7922f506-90d8-4199-9444-4279c3d5c328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 31 14:14:23 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# First let's check what has Google given us ! Thank you Google for the GPU\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24198,
     "status": "ok",
     "timestamp": 1577806085311,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "Dj2NshHKZ5gX",
    "outputId": "fb3b391c-db03-442a-fdda-fff1e88fccad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Let's mount our G-Drive. Hey !! Because for GPU you now give your data to Google \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74682,
     "status": "ok",
     "timestamp": 1577806001488,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "nK7yth0BZ7T-",
    "outputId": "826803db-62bc-46d3-b7d9-355009bd6b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiny-tokenizer\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/0f/aa52c227c5af69914be05723b3deaf221805a4ccbce87643194ef2cdde43/tiny_tokenizer-3.1.0.tar.gz\n",
      "Building wheels for collected packages: tiny-tokenizer\n",
      "  Building wheel for tiny-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tiny-tokenizer: filename=tiny_tokenizer-3.1.0-cp36-none-any.whl size=10550 sha256=58a4751f88c984e23a7342dd0be9729e53dabcc86c46e98791474c4081c2ab20\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/c8/36/334497a689fab90128232e86b5829b800dd271a3d5d5959c53\n",
      "Successfully built tiny-tokenizer\n",
      "Installing collected packages: tiny-tokenizer\n",
      "Successfully installed tiny-tokenizer-3.1.0\n",
      "Collecting flair\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/22/8fc8e5978ec05b710216735ca47415700e83f304dec7e4281d61cefb6831/flair-0.4.4-py3-none-any.whl (193kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: tiny-tokenizer[all] in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.0)\n",
      "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.3.1)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n",
      "Collecting langdetect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 71.1MB/s \n",
      "\u001b[?25hCollecting mpld3==0.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K     |████████████████████████████████| 798kB 58.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.9)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
      "Collecting ipython==7.6.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n",
      "\u001b[K     |████████████████████████████████| 778kB 52.8MB/s \n",
      "\u001b[?25hCollecting segtok>=1.5.7\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from flair) (3.10.0)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
      "Collecting transformers>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 57.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.2)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
      "Collecting bpemb>=0.2.9\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Collecting kytea; extra == \"all\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/bc/702d01a96d5d094bd9f3c2eb1d12153daf8edf7bf5d78b9a2dae1202df07/kytea-0.1.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 45.0MB/s \n",
      "\u001b[?25hCollecting janome; extra == \"all\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/f0/bd7f90806132d7d9d642d418bdc3e870cfdff5947254ea3cab27480983a7/Janome-0.3.10-py2.py3-none-any.whl (21.5MB)\n",
      "\u001b[K     |████████████████████████████████| 21.5MB 152kB/s \n",
      "\u001b[?25hCollecting SudachiDict-core@ https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz ; extra == \"all\"\n",
      "\u001b[?25l  Downloading https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz (70.7MB)\n",
      "\u001b[K     |████████████████████████████████| 70.7MB 36kB/s \n",
      "\u001b[?25hCollecting natto-py; extra == \"all\"\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/14/1d4258247a00b7b8a115563effb1d0bd30501d69580629d36593ce0af92d/natto-py-0.9.2.tar.gz\n",
      "Collecting sentencepiece; extra == \"all\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 52.4MB/s \n",
      "\u001b[?25hCollecting SudachiPy; extra == \"all\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/c9/40bfb291a7995ad218451ef97083432f998b822e3ecbd9f586f593d2cfb6/SudachiPy-0.4.2-py3-none-any.whl (73kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 13.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (1.17.4)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.3.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.6.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (8.0.2)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (42.0.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n",
      "Collecting prompt-toolkit<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl (340kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 73.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (2.21.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
      "\u001b[K     |████████████████████████████████| 860kB 61.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.10.40)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (4.3.0)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (1.13.2)\n",
      "Collecting dartsclone~=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/4d/45acbe9d0795d8ceef0fee1f9ac2dcbf27dca3a0578a023fcdc3fef6fd89/dartsclone-0.6.tar.gz\n",
      "Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (2.1.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2019.11.28)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (0.14.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (1.13.40)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.9.4)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->flair) (0.46)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (2.19)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.6.0->SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.29.14)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers>=2.0.0->flair) (0.15.2)\n",
      "Building wheels for collected packages: langdetect, mpld3, sqlitedict, segtok, SudachiDict-core, natto-py, sacremoses, dartsclone\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=8713dd640de284539a6041e85cee0371f89bd0d27ce39d671c0ff75b9d25a67a\n",
      "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=27d743fb1c0c6ce89021a7e61916483583607d62a6d473bb5c614850a9d0e671\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=a0495e6cc6c0aa0114af0ef1ef24cf924b7062b3211df5c5e9e03d1c3aa3e076\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=f3fb3071610b4e76d3671f66fd0774f5e48e7a672e6e80272eb13d33a6562b14\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
      "  Building wheel for SudachiDict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for SudachiDict-core: filename=SudachiDict_core-20190927-cp36-none-any.whl size=70878518 sha256=1b40c266029171617cb750055038be7836600bc22938c35fe6f28cdc489de808\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/d8/6e/b107d7fef6e80915aa1e46db741b98a3da011f567526347ccc\n",
      "  Building wheel for natto-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for natto-py: filename=natto_py-0.9.2-cp36-none-any.whl size=45164 sha256=4e202bd4faa85e0b153d15409106eb90b3e995db639c71a4bb2165d5617de4b9\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/51/dd/67f87608b124a23eecf5c1fc3557cc0b7ffdeae33fe6ee89df\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=5b9a9fde7ef89f05f0aee3629336e7c05d6ab2c13cb5f69d21a3645b1242d76b\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
      "  Building wheel for dartsclone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for dartsclone: filename=dartsclone-0.6-cp36-cp36m-linux_x86_64.whl size=413265 sha256=dd875a8fc63cf6663b029a475a832f17959127ad33ae0ed3d69d15af038b1303\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/cd/70/fe43307bf7398243155108f4f5a258ef336923d65ec4af93cd\n",
      "Successfully built langdetect mpld3 sqlitedict segtok SudachiDict-core natto-py sacremoses dartsclone\n",
      "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: langdetect, mpld3, sqlitedict, prompt-toolkit, ipython, segtok, sacremoses, sentencepiece, transformers, deprecated, bpemb, flair, kytea, janome, dartsclone, SudachiPy, SudachiDict-core, natto-py\n",
      "  Found existing installation: prompt-toolkit 1.0.18\n",
      "    Uninstalling prompt-toolkit-1.0.18:\n",
      "      Successfully uninstalled prompt-toolkit-1.0.18\n",
      "  Found existing installation: ipython 5.5.0\n",
      "    Uninstalling ipython-5.5.0:\n",
      "      Successfully uninstalled ipython-5.5.0\n",
      "Successfully installed SudachiDict-core-20190927 SudachiPy-0.4.2 bpemb-0.3.0 dartsclone-0.6 deprecated-1.2.7 flair-0.4.4 ipython-7.6.1 janome-0.3.10 kytea-0.1.4 langdetect-1.0.7 mpld3-0.3 natto-py-0.9.2 prompt-toolkit-2.0.10 sacremoses-0.0.35 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0 transformers-2.3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "IPython",
         "prompt_toolkit"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install necessary packages and restart the environment\n",
    "\n",
    "!pip install tiny-tokenizer\n",
    "!pip install  flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3683,
     "status": "ok",
     "timestamp": 1577806038274,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "TaDyGj3-Z9G_",
    "outputId": "ffdc1ffe-883e-4eaf-dcc6-9eb6add18262"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's import our packages !\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import html\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import flair\n",
    "import pickle\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "# The sentence objects holds a sentence that we may want to embed or tag\n",
    "from flair.data import Sentence\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.samplers import ImbalancedClassificationDatasetSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TiTzjVxGGva"
   },
   "source": [
    "# 1. Text Pre-processing\n",
    "\n",
    "### Note -\n",
    "We need to be careful to apply the same set of text transformations during inference as we did during training. Any changes will directly affect the model to produce junk / more junky results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJDMNIrNjRUC"
   },
   "outputs": [],
   "source": [
    "clean = re.compile('<.*?>')\n",
    "\n",
    "def preprocess_text(text) :\n",
    "  try :\n",
    "    # soup = BeautifulSoup(text, \"html.parser\")\n",
    "    # text = soup.get_text()\n",
    "    text=  re.sub(clean, '', text)\n",
    "    text = html.unescape(text)\n",
    "  except :\n",
    "    print(\"Error in HTML Processing ...\")\n",
    "    print(text)\n",
    "    text = text\n",
    "  try :\n",
    "    # remove extra newlines (often might be present in really noisy text)\n",
    "    text = text.translate(text.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "  except :\n",
    "    print(\"Error in removing extra lines ...\")\n",
    "    print(text)\n",
    "    text = text\n",
    "\n",
    "  try :\n",
    "    # remove extra whitespace\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.strip()\n",
    "  except :\n",
    "    print(\"Error in extra whitespace removal ...\")\n",
    "    print(text)\n",
    "    text = text\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_P-qJxsRIalP"
   },
   "source": [
    "# 2. Load Classifiers\n",
    "\n",
    "We iterate through the saved classifiers and load them. We append them in a list can be easily iterated during evaluation/prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 390771,
     "status": "ok",
     "timestamp": 1577806481884,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "IQoJposoZ_ba",
    "outputId": "e908502e-2c66-4b87-e798-0fb5ac4903e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:28:13,097 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/1/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1/14 [00:22<04:51, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:28:35,497 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/2/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 2/14 [00:47<04:37, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:29:00,334 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/3/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 3/14 [00:54<03:21, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:29:07,280 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/4/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 4/14 [01:26<03:44, 22.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:29:39,552 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/5/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 5/14 [02:00<03:54, 26.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:30:13,938 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/6/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 6/14 [02:24<03:23, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:30:37,886 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/7/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 7/14 [02:54<03:06, 26.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:31:07,491 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/8/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 8/14 [03:24<02:47, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:31:38,040 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/9/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 9/14 [03:51<02:17, 27.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:32:04,947 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/10/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 10/14 [04:21<01:53, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:32:34,855 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/11/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 11/14 [04:49<01:24, 28.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:33:02,677 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/12/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 12/14 [05:21<00:58, 29.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:33:34,520 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/13/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 13/14 [05:52<00:29, 29.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31 15:34:05,240 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised_training_data/group/14/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 14/14 [06:27<00:00, 31.37s/it]\n"
     ]
    }
   ],
   "source": [
    "classifiers  = []\n",
    "\n",
    "for grp_id in tqdm(range(1,15)) :\n",
    "  path  = '/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/' + str(grp_id) + '/best-model.pt'\n",
    "  classifier = TextClassifier.load(path)\n",
    "  classifiers.append(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adum5OoFKFrj"
   },
   "source": [
    "# 3. Load Test Data & Preprocess\n",
    "\n",
    "We load the test-data from the previously created split and re-transform it into a Dataframe with corresponding labels.\n",
    "\n",
    "Finally we save the DataFrame with a placeholder for the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3WJPPPEam39"
   },
   "outputs": [],
   "source": [
    "test_data = '/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/test.txt'\n",
    "\n",
    "with open(test_data,'r',encoding='utf-8') as f :\n",
    "  data = f.readlines()\n",
    "\n",
    "# prefix from the Training Data Format\n",
    "prefix = '__label__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6068,
     "status": "ok",
     "timestamp": 1577418263037,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "e_5OHx2bfNR4",
    "outputId": "4fee29ee-49a5-448b-ac50-b5be7a713f69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157799/157799 [00:02<00:00, 71856.09it/s]\n"
     ]
    }
   ],
   "source": [
    "test_text = []\n",
    "test_label = []\n",
    "for doc in tqdm(data) :\n",
    "  splits =  doc.split()\n",
    "  labels = []\n",
    "  idx = 0 \n",
    "  for word in splits :\n",
    "    if prefix in word :\n",
    "      labels.append(word[9:].strip())\n",
    "      idx += len(word)\n",
    "    else :\n",
    "      text = doc[idx:].strip()\n",
    "      break\n",
    "  test_text.append(text)\n",
    "  test_label.append(labels)\n",
    "  # break\n",
    "\n",
    "test_df = pd.DataFrame(list(zip(test_text,test_label)),columns = ['text','original_labels'])\n",
    "test_df['predicted_labels'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qOd1JBJfUSd"
   },
   "outputs": [],
   "source": [
    "test_df.to_pickle('/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/test.pkl')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjbU5xK3PjX4"
   },
   "source": [
    "# 4. Run the Ensemble Pipeline\n",
    "\n",
    "Once we load the test-data, we can iteratively run it via all the classifiers and store the predictions for evaluating the performance.\n",
    "\n",
    "### Coding Exercise # X\n",
    "  1. Multi-thread/process the prediction pipeline.\n",
    "  2. Find a redundant line of code in the cell below\n",
    "  3. Optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "medRbiboaPgi"
   },
   "outputs": [],
   "source": [
    "# Read the cleaned Test Data for running with different classifiers & threshold\n",
    "\n",
    "with open('/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/test.pkl','rb') as f :\n",
    "  test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17534134,
     "status": "ok",
     "timestamp": 1577824105653,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "shBmO5bUilhV",
    "outputId": "e0e7e773-9fd0-486d-b6b2-42cebfe6acd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 134329/157799 [4:09:11<53:03,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "## Setting a global threshold for all classifiers\n",
    "threshold = 0.9\n",
    "\n",
    "## Iterating through each Test Example\n",
    "for idx in tqdm(test_df.index) :\n",
    "  text = preprocess_text(test_df.loc[idx,'text'])\n",
    "  \n",
    "  # create example sentence\n",
    "  sentence = Sentence(text)\n",
    "  labels = []\n",
    "\n",
    "  ## Iterate through each classifier or prediction\n",
    "  for classifier in classifiers:\n",
    "    classifier.multi_label_threshold = threshold\n",
    "    classifier.predict(sentence)\n",
    "\n",
    "    for label in sentence.labels :\n",
    "      ## Append labels from all classifiers\n",
    "      labels.append(label.value)\n",
    "\n",
    "  test_df.at[idx,'predicted_labels'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1619,
     "status": "ok",
     "timestamp": 1577824107256,
     "user": {
      "displayName": "Amit Agarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64",
      "userId": "15805199744168269697"
     },
     "user_tz": -330
    },
    "id": "T7GDcELekzEJ",
    "outputId": "04939e6c-9957-446f-9360-60784e02867d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>original_labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More Efficient way to code if then else statem...</td>\n",
       "      <td>[c++]</td>\n",
       "      <td>[testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p\\t\"Make appear at current scroll position. Ok...</td>\n",
       "      <td>[javascript, php]</td>\n",
       "      <td>[go, testing, tdd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Symbol(s) not found for architecture i386 - M...</td>\n",
       "      <td>[xcode]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google PlusOneButton not compatible with Insta...</td>\n",
       "      <td>[android]</td>\n",
       "      <td>[android, testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on\\t\"How to install MySql-python-1.2.3 on Mac ...</td>\n",
       "      <td>[osx, mysql, python]</td>\n",
       "      <td>[testing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ...    predicted_labels\n",
       "0  More Efficient way to code if then else statem...  ...           [testing]\n",
       "1  p\\t\"Make appear at current scroll position. Ok...  ...  [go, testing, tdd]\n",
       "2  \"Symbol(s) not found for architecture i386 - M...  ...                  []\n",
       "3  Google PlusOneButton not compatible with Insta...  ...  [android, testing]\n",
       "4  on\\t\"How to install MySql-python-1.2.3 on Mac ...  ...           [testing]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the predicteions\n",
    "test_df.to_pickle('/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/normalised_test_predcted_th_0'+ str(int(threshold*10)) +'.pkl')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-jgM2QLtgWy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "inference_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
