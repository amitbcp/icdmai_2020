{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6_inference_pipeline.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"S10Vu9D_HTxK","colab_type":"text"},"source":["# Perdiction Pipeline | Ensemble Pipeline\n","\n","In this notebook, we will ensemble our models to make a prediction pipeline.\n","The keys steps would be as following :\n","\n","  1. Text Preprocessing for inference.\n","  2. Load classifiers iteratively in a list.\n","  3. Load test-data & pre-process.\n","  4. Set classifier threshold and run it through Ensemble\n","\n"]},{"cell_type":"code","metadata":{"id":"tWSz_ii0ZUiL","colab_type":"code","outputId":"43fe2961-cb2f-4696-a47d-bc355c564d9a","executionInfo":{"status":"ok","timestamp":1578936597412,"user_tz":-330,"elapsed":4974,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["# First let's check what has Google given us ! Thank you Google for the GPU\n","\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mon Jan 13 17:29:56 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dj2NshHKZ5gX","colab_type":"code","outputId":"133f579e-5097-45d3-ea21-3555818a8bde","executionInfo":{"status":"ok","timestamp":1578936631470,"user_tz":-330,"elapsed":34486,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Let's mount our G-Drive. Hey !! Because for GPU you now give your data to Google \n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nK7yth0BZ7T-","colab_type":"code","outputId":"c545adf6-062c-4835-e9db-a48b34fadba4","executionInfo":{"status":"ok","timestamp":1578936704782,"user_tz":-330,"elapsed":74590,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Install necessary packages and restart the environment\n","\n","!pip install tiny-tokenizer\n","!pip install  flair"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tiny-tokenizer\n","  Downloading https://files.pythonhosted.org/packages/8d/0f/aa52c227c5af69914be05723b3deaf221805a4ccbce87643194ef2cdde43/tiny_tokenizer-3.1.0.tar.gz\n","Building wheels for collected packages: tiny-tokenizer\n","  Building wheel for tiny-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tiny-tokenizer: filename=tiny_tokenizer-3.1.0-cp36-none-any.whl size=10550 sha256=c0ca89bccd7511da93e1bb1efdf7ec0527fb87a267de83cce971ec0242e1d196\n","  Stored in directory: /root/.cache/pip/wheels/d1/c8/36/334497a689fab90128232e86b5829b800dd271a3d5d5959c53\n","Successfully built tiny-tokenizer\n","Installing collected packages: tiny-tokenizer\n","Successfully installed tiny-tokenizer-3.1.0\n","Collecting flair\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/22/8fc8e5978ec05b710216735ca47415700e83f304dec7e4281d61cefb6831/flair-0.4.4-py3-none-any.whl (193kB)\n","\u001b[K     |████████████████████████████████| 194kB 2.7MB/s \n","\u001b[?25hCollecting mpld3==0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n","\u001b[K     |████████████████████████████████| 798kB 64.5MB/s \n","\u001b[?25hCollecting segtok>=1.5.7\n","  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n","Requirement already satisfied: tiny-tokenizer[all] in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.0)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n","Collecting deprecated>=1.2.4\n","  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n","Collecting sqlitedict>=1.6.0\n","  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n","Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.3.1)\n","Collecting ipython==7.6.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n","\u001b[K     |████████████████████████████████| 778kB 62.1MB/s \n","\u001b[?25hCollecting bpemb>=0.2.9\n","  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from flair) (3.10.0)\n","Collecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n","\u001b[K     |████████████████████████████████| 1.0MB 51.2MB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.2)\n","Collecting transformers>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\u001b[K     |████████████████████████████████| 450kB 53.7MB/s \n","\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n","Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.22.1)\n","Collecting janome; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/f0/bd7f90806132d7d9d642d418bdc3e870cfdff5947254ea3cab27480983a7/Janome-0.3.10-py2.py3-none-any.whl (21.5MB)\n","\u001b[K     |████████████████████████████████| 21.5MB 156kB/s \n","\u001b[?25hCollecting sentencepiece; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 68.1MB/s \n","\u001b[?25hCollecting kytea; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/bc/702d01a96d5d094bd9f3c2eb1d12153daf8edf7bf5d78b9a2dae1202df07/kytea-0.1.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 57.9MB/s \n","\u001b[?25hCollecting SudachiDict-core@ https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz ; extra == \"all\"\n","\u001b[?25l  Downloading https://object-storage.tyo2.conoha.io/v1/nc_2520839e1f9641b08211a5c85243124a/sudachi/SudachiDict_core-20190927.tar.gz (70.7MB)\n","\u001b[K     |████████████████████████████████| 70.7MB 32kB/s \n","\u001b[?25hCollecting SudachiPy; extra == \"all\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/c9/40bfb291a7995ad218451ef97083432f998b822e3ecbd9f586f593d2cfb6/SudachiPy-0.4.2-py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n","\u001b[?25hCollecting natto-py; extra == \"all\"\n","  Downloading https://files.pythonhosted.org/packages/f1/14/1d4258247a00b7b8a115563effb1d0bd30501d69580629d36593ce0af92d/natto-py-0.9.2.tar.gz\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.17.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (8.0.2)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (42.0.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.1)\n","Collecting prompt-toolkit<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl (340kB)\n","\u001b[K     |████████████████████████████████| 348kB 39.7MB/s \n","\u001b[?25hRequirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.21.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (6.2.2)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 64.0MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.10.47)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.6.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.14.1)\n","Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (2.1.0)\n","Collecting dartsclone~=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/7d/4d/45acbe9d0795d8ceef0fee1f9ac2dcbf27dca3a0578a023fcdc3fef6fd89/dartsclone-0.6.tar.gz\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (1.13.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.8)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n","Requirement already satisfied: parso>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.2)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2019.11.28)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (7.0)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (1.13.47)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.2.1)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.6.0->SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.29.14)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (2.19)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers>=2.0.0->flair) (0.15.2)\n","Building wheels for collected packages: mpld3, segtok, sqlitedict, langdetect, SudachiDict-core, natto-py, sacremoses, dartsclone\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=c833269c3148db363c2b1433af765508367cc8b1f74a25fd813c5cfa30ed07e5\n","  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=4bf32c6fd495c71bbc98f3928dced85206ecbcf1ff09cc381ac3222c85afaad5\n","  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=eff39818e020bc8a61944d6ffbeebe9d0d3940734c9101d88ff3d4834cbf7be0\n","  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=02e4aa3543ed5b39afc5d1c31babe421703454ec01ac69ffa78e9ef54381091d\n","  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n","  Building wheel for SudachiDict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for SudachiDict-core: filename=SudachiDict_core-20190927-cp36-none-any.whl size=70878518 sha256=ed69b47817e20389929836db3e8a597f525fb2f6fd2f0fef0e7a5b526883ea36\n","  Stored in directory: /root/.cache/pip/wheels/22/d8/6e/b107d7fef6e80915aa1e46db741b98a3da011f567526347ccc\n","  Building wheel for natto-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for natto-py: filename=natto_py-0.9.2-cp36-none-any.whl size=45164 sha256=c9918525fc1733d72223003928634b4cc18407c3a48fe551819f14c01add22c4\n","  Stored in directory: /root/.cache/pip/wheels/ce/51/dd/67f87608b124a23eecf5c1fc3557cc0b7ffdeae33fe6ee89df\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=a7e4969c39be605f1c0aecb84ff3ae19305212a51aa8feef47eb4355b5cb14c8\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","  Building wheel for dartsclone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dartsclone: filename=dartsclone-0.6-cp36-cp36m-linux_x86_64.whl size=413259 sha256=76fbafff9a52cefed54828e53ba95e120fddf6e0f4298510a1c3ab12c101bc29\n","  Stored in directory: /root/.cache/pip/wheels/be/cd/70/fe43307bf7398243155108f4f5a258ef336923d65ec4af93cd\n","Successfully built mpld3 segtok sqlitedict langdetect SudachiDict-core natto-py sacremoses dartsclone\n","\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n","Installing collected packages: mpld3, segtok, deprecated, sqlitedict, prompt-toolkit, ipython, sentencepiece, bpemb, langdetect, sacremoses, transformers, flair, janome, kytea, dartsclone, SudachiPy, SudachiDict-core, natto-py\n","  Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","Successfully installed SudachiDict-core-20190927 SudachiPy-0.4.2 bpemb-0.3.0 dartsclone-0.6 deprecated-1.2.7 flair-0.4.4 ipython-7.6.1 janome-0.3.10 kytea-0.1.4 langdetect-1.0.7 mpld3-0.3 natto-py-0.9.2 prompt-toolkit-2.0.10 sacremoses-0.0.38 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0 transformers-2.3.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"TaDyGj3-Z9G_","colab_type":"code","outputId":"4ec43f8f-12aa-400a-b71a-a33231f952b7","executionInfo":{"status":"ok","timestamp":1578936728004,"user_tz":-330,"elapsed":6877,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["# Let's import our packages !\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import html\n","import re\n","from bs4 import BeautifulSoup\n","import re\n","from sklearn.model_selection import train_test_split\n","# import flair\n","import pickle\n","from torch.optim.adam import Adam\n","\n","# The sentence objects holds a sentence that we may want to embed or tag\n","from flair.data import Sentence\n","from flair.data import Corpus\n","from flair.datasets import ClassificationCorpus\n","from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer\n","from flair.samplers import ImbalancedClassificationDatasetSampler"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"2TiTzjVxGGva","colab_type":"text"},"source":["# 1. Text Pre-processing\n","\n","### Note -\n","We need to be careful to apply the same set of text transformations during inference as we did during training. Any changes will directly affect the model to produce junk / more junky results"]},{"cell_type":"code","metadata":{"id":"WJDMNIrNjRUC","colab_type":"code","colab":{}},"source":["clean = re.compile('<.*?>')\n","\n","def preprocess_text(text) :\n","  try :\n","    # soup = BeautifulSoup(text, \"html.parser\")\n","    # text = soup.get_text()\n","    text=  re.sub(clean, '', text)\n","    text = html.unescape(text)\n","  except :\n","    print(\"Error in HTML Processing ...\")\n","    print(text)\n","    text = text\n","  try :\n","    # remove extra newlines (often might be present in really noisy text)\n","    text = text.translate(text.maketrans(\"\\n\\t\\r\", \"   \"))\n","  except :\n","    print(\"Error in removing extra lines ...\")\n","    print(text)\n","    text = text\n","\n","  try :\n","    # remove extra whitespace\n","    text = re.sub(' +', ' ', text)\n","    text = text.strip()\n","  except :\n","    print(\"Error in extra whitespace removal ...\")\n","    print(text)\n","    text = text\n","\n","  return text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_P-qJxsRIalP","colab_type":"text"},"source":["# 2. Load Classifiers\n","\n","We iterate through the saved classifiers and load them. We append them in a list can be easily iterated during evaluation/prediction."]},{"cell_type":"code","metadata":{"id":"IQoJposoZ_ba","colab_type":"code","outputId":"b9f7eb56-5f7a-45ba-bc5b-8516f89088e0","executionInfo":{"status":"ok","timestamp":1578937117041,"user_tz":-330,"elapsed":379813,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["classifiers  = []\n","\n","for grp_id in tqdm(range(1,15)) :\n","  path  = '/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/' + str(grp_id) + '/best-model.pt'\n","  classifier = TextClassifier.load(path)\n","  classifiers.append(classifier)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/14 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:32:19,739 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/1/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r  7%|▋         | 1/14 [00:19<04:10, 19.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:32:39,018 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/2/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 14%|█▍        | 2/14 [00:46<04:21, 21.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:33:06,616 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/3/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 21%|██▏       | 3/14 [00:56<03:20, 18.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:33:16,632 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/4/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 29%|██▊       | 4/14 [01:21<03:22, 20.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:33:41,682 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/5/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 36%|███▌      | 5/14 [01:53<03:31, 23.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:34:12,777 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/6/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 43%|████▎     | 6/14 [02:23<03:23, 25.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:34:42,741 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/7/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 7/14 [02:50<03:02, 26.11s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:35:10,354 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/8/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 57%|█████▋    | 8/14 [03:19<02:41, 26.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:35:38,974 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/9/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 64%|██████▍   | 9/14 [03:49<02:19, 27.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:36:09,186 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/10/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 71%|███████▏  | 10/14 [04:20<01:55, 28.79s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:36:40,135 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/11/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 79%|███████▊  | 11/14 [04:46<01:24, 28.09s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:37:06,590 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/12/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 86%|████████▌ | 12/14 [05:17<00:57, 28.78s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:37:36,993 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/13/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 93%|█████████▎| 13/14 [05:50<00:30, 30.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["2020-01-13 17:38:09,865 loading file /content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/normalised/group/14/best-model.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 14/14 [06:18<00:00, 29.41s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"adum5OoFKFrj","colab_type":"text"},"source":["# 3. Load Test Data & Preprocess\n","\n","We load the test-data from the previously created split and re-transform it into a Dataframe with corresponding labels.\n","\n","Finally we save the DataFrame with a placeholder for the predicted labels."]},{"cell_type":"code","metadata":{"id":"j3WJPPPEam39","colab_type":"code","colab":{}},"source":["test_data = '/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/test.txt'\n","\n","with open(test_data,'r',encoding='utf-8') as f :\n","  data = f.readlines()\n","\n","# prefix from the Training Data Format\n","prefix = '__label__'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e_5OHx2bfNR4","colab_type":"code","outputId":"4fee29ee-49a5-448b-ac50-b5be7a713f69","executionInfo":{"status":"ok","timestamp":1577418263037,"user_tz":-330,"elapsed":6068,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_text = []\n","test_label = []\n","for doc in tqdm(data) :\n","  splits =  doc.split()\n","  labels = []\n","  idx = 0 \n","  for word in splits :\n","    if prefix in word :\n","      labels.append(word[9:].strip())\n","      idx += len(word)\n","    else :\n","      text = doc[idx:].strip()\n","      break\n","  test_text.append(text)\n","  test_label.append(labels)\n","  # break\n","\n","test_df = pd.DataFrame(list(zip(test_text,test_label)),columns = ['text','original_labels'])\n","test_df['predicted_labels'] = None\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 157799/157799 [00:02<00:00, 71856.09it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0qOd1JBJfUSd","colab_type":"code","colab":{}},"source":["test_df.to_pickle('/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/test.pkl')\n","test_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LjbU5xK3PjX4","colab_type":"text"},"source":["# 4. Run the Ensemble Pipeline\n","\n","Once we load the test-data, we can iteratively run it via all the classifiers and store the predictions for evaluating the performance.\n","\n","### Coding Exercise \n","  1. Multi-thread/process the prediction pipeline.\n","  2. Find a redundant line of code in the cell below\n","  3. Optimize it"]},{"cell_type":"code","metadata":{"id":"rD7TvcWZ_GSJ","colab_type":"code","colab":{}},"source":["def predict_ensemble(sentence,threshold=0.1) :\n","  labels  = [] \n","  ## Iterate through each classifier or prediction\n","  for classifier in classifiers:\n","    classifier.multi_label_threshold = threshold\n","    classifier.predict(sentence)\n","    for label in sentence.labels :\n","      ## Append labels from all classifiers\n","      labels.append(label.value)\n","  return labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"medRbiboaPgi","colab_type":"code","colab":{}},"source":["# Read the cleaned Test Data for running with different classifiers & threshold\n","\n","with open('/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/test.pkl','rb') as f :\n","  test_df = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"shBmO5bUilhV","colab_type":"code","outputId":"e0e7e773-9fd0-486d-b6b2-42cebfe6acd1","executionInfo":{"status":"ok","timestamp":1577824105653,"user_tz":-330,"elapsed":17534134,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## Setting a global threshold for all classifiers\n","threshold = 0.9\n","\n","## Iterating through each Test Example\n","for idx in tqdm(test_df.index) :\n","  text = preprocess_text(test_df.loc[idx,'text'])\n","  \n","  # create example sentence\n","  sentence = Sentence(text)\n","  labels = []\n","\n","  ## Iterate through each classifier or prediction\n","  for classifier in classifiers:\n","    classifier.multi_label_threshold = threshold\n","    classifier.predict(sentence)\n","\n","    for label in sentence.labels :\n","      ## Append labels from all classifiers\n","      labels.append(label.value)\n","\n","  test_df.at[idx,'predicted_labels'] = labels\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" 85%|████████▌ | 134329/157799 [4:09:11<53:03,  7.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T7GDcELekzEJ","colab_type":"code","colab":{}},"source":["# Save the predictions\n","test_df.to_pickle('/content/drive/My Drive/ICDMAI_Tutorial/notebook/training_data/70_30_split/normalised_test_predcted_th_0'+ str(int(threshold*10)) +'.pkl')\n","test_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pzw1zSe-Fm-G","colab_type":"text"},"source":["# Let's Infer !\n","\n","Let's manually create some text/questions and ask the model about it."]},{"cell_type":"code","metadata":{"id":"I-jgM2QLtgWy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"777e91db-e4fa-4e7f-9468-88e3f6f5d73f","executionInfo":{"status":"ok","timestamp":1578938687702,"user_tz":-330,"elapsed":1596,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}}},"source":["text1 = preprocess_text(\"How to handle memory locking ?\")\n","# create example sentence & tokenize\n","sentence1 = Sentence(text1)\n","# predict\n","labels = predict_ensemble(sentence1,threshold=0.8)\n","print(labels)\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["['haskell', 'testing']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BD3c-9ij_fow","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9e5ff8fe-fc83-4f0a-f07e-00255968655e","executionInfo":{"status":"ok","timestamp":1578938681991,"user_tz":-330,"elapsed":1626,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}}},"source":["text2 = preprocess_text(\"How to handle memory locking in java ?\")\n","# create example sentence & tokenize\n","sentence2 = Sentence(text2)\n","# predict\n","labels = predict_ensemble(sentence2,threshold=0.8)\n","print(labels)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["['haskell', 'testing']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TA9km3X6_406","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"616376bb-d0c3-4dc0-938c-ecd5c7c35e6f","executionInfo":{"status":"ok","timestamp":1578938692789,"user_tz":-330,"elapsed":745,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}}},"source":["text3 = preprocess_text(\"How to handle memory locking in java python ?\")\n","# create example sentence & tokenize\n","sentence3 = Sentence(text3)\n","# predict\n","labels = predict_ensemble(sentence3,threshold=0.8)\n","print(labels)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["['testing', 'excel']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Se5TGVXBAOnH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"26192290-0c01-4506-a25b-577835d63e18","executionInfo":{"status":"ok","timestamp":1578938709270,"user_tz":-330,"elapsed":1595,"user":{"displayName":"Amit Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCNCK3WDEC63aFcnBVJrUB3M3cs4J2bImVRkNad8A=s64","userId":"15805199744168269697"}}},"source":["text4 = preprocess_text(\"This post is not about java\")\n","# create example sentence & tokenize\n","sentence4 = Sentence(text4)\n","# predict\n","labels = predict_ensemble(sentence4,threshold=0.8)\n","print(labels)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["['typescript', 'haskell', 'testing']\n"],"name":"stdout"}]}]}